{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PROCESS\n",
        "- Data Import \n",
        "- Preprocessing for Business Logic\n",
        "- Preprocessing for Model\n",
        "- Modeling\n",
        "- Training\n",
        "- Validation \n",
        "- Inference\n",
        "- Postprocessing\n",
        "- Packaging\n",
        "- Serving\n",
        "- Monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7832fpZsQY53"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import defaultdict\n",
        "\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.getcwd()\n",
        "os.chdir('..')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D58cPm5HY_zF"
      },
      "outputs": [],
      "source": [
        "ratings = pd.read_csv('dataset/ratings.csv').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User number: 610, Item number: 9724, Interaction number: 100836, Sparsity: 0.9830\n"
          ]
        }
      ],
      "source": [
        "user_num = ratings['userId'].nunique()\n",
        "item_num = ratings['movieId'].nunique()\n",
        "interaction_num = len(ratings)\n",
        "sparsity = 1 - interaction_num / (user_num * item_num)\n",
        "print('User number: %d, Item number: %d, Interaction number: %d, Sparsity: %.4f' % (user_num, item_num, interaction_num, sparsity))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count     610.000000\n",
              "mean      165.304918\n",
              "std       269.480584\n",
              "min        20.000000\n",
              "25%        35.000000\n",
              "50%        70.500000\n",
              "75%       168.000000\n",
              "max      2698.000000\n",
              "dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 유저 한 명당 몇 개의 아이템을 소비했는가?\n",
        "ratings.groupby('userId').size().describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "rating\n",
              "5.0    0.131015\n",
              "4.5    0.084801\n",
              "4.0    0.265957\n",
              "3.5    0.130271\n",
              "3.0    0.198808\n",
              "2.5    0.055040\n",
              "2.0    0.074884\n",
              "1.5    0.017762\n",
              "1.0    0.027877\n",
              "0.5    0.013586\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings['rating'].value_counts(normalize=True).sort_index(ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PROCESS\n",
        "- Configuration\n",
        "- Data Import \n",
        "- Preprocessing for Business Logic\n",
        "- Preprocessing for Model\n",
        "- Training\n",
        "- Validation \n",
        "- Inference\n",
        "- Postprocessing\n",
        "- Packaging\n",
        "- Serving\n",
        "- Monitoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### CONFIGURATION\n",
        "- 서비스에 필요한 모든 config를 제어할 수 있게 만드는 파트\n",
        "- dev - stage - live 등의 환경 분리\n",
        "- 모델 하이퍼 파라미터 관리\n",
        "- 서비스 관련된 파라미터 관리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    'num_epoch': 10,\n",
        "    'batch_size': 256,\n",
        "    'lr': 0.001,\n",
        "    'topk': 10,\n",
        "    'valid_sample_size' : 10, \n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Data Import\n",
        "- 학습 데이터를 import 하는 단계\n",
        "- 학습 데이터를 만들어주는 DE 작업(Batch, Feature Store 등..)이 필요함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "ratings = pd.read_csv('dataset/ratings.csv').reset_index(drop=True)\n",
        "# side information 적용 시 사용\n",
        "movies = pd.read_csv('dataset/movies.csv').reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Preprocessing For Business Logic\n",
        "- 비즈니스 로직과 관련된 전처리 작업\n",
        "  - e.g. 5점 척도를 0,1로 만들건데 3점 이상은 1로 처리할까요?\n",
        "  - e.g. 어뷰저의 명단이 있다면 제외하는 것이 어때요?\n",
        "  - e.g. 너무 인기없는 아이템은 제외할까요? \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# columns standardization\n",
        "ratings.rename(columns={'userId': 'user_id', 'movieId': 'item_id'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3점 이상을 positive(=1)로, 3점 미만을 negative(=0)로\n",
        "ratings['interaction'] = np.where(ratings['rating'] >= 3, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "interaction\n",
              "1    0.810851\n",
              "0    0.189149\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings['interaction'].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Preprocessing For Model\n",
        "- 모델의 input을 가공하기 위한 전처리 작업\n",
        "  - Encoding / Embedding?\n",
        "  - side information 포함 여부\n",
        "- Dataset 인스턴스를 만들어서 DataLoader에 주입\n",
        "  - Model에게 데이터를 어떻게 전달할 것인지 정의\n",
        "  - Train Dataset과 Validation Dataset을 구분"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AEDataSet(Dataset):\n",
        "    def __init__(self, ratings):\n",
        "        self.ratings = ratings\n",
        "        self.user_num = ratings['user_id'].nunique()\n",
        "        self.item_num = ratings['item_id'].nunique()\n",
        "        self.users = [i for i in range(self.user_num)]\n",
        "        self.user2idx = self._encode(ratings, 'user_id')\n",
        "        self.idx2user = self._decode(ratings, 'user_id')\n",
        "        self.item2idx = self._encode(ratings, 'item_id')\n",
        "        self.idx2item = self._decode(ratings, 'item_id')\n",
        "\n",
        "        self.ratings['user_idx'] = self.ratings['user_id'].map(self.user2idx)\n",
        "        self.ratings['item_idx'] = self.ratings['item_id'].map(self.item2idx)\n",
        "\n",
        "        self.user_item_dict = self.get_user_item_dict()\n",
        "        self.train_dict, self.valid_dict = self.train_valid_split()\n",
        "\n",
        "            \n",
        "    def _encode(self, df:pd.DataFrame, feature:str):\n",
        "        \"\"\"\n",
        "        feature를 index로 변환하는 함수\n",
        "        \"\"\"\n",
        "        return {val: idx for idx, val in enumerate(df[feature].unique())}\n",
        "    \n",
        "    def _decode(self, df:pd.DataFrame, feature:str):\n",
        "        \"\"\"\n",
        "        index를 feature로 변환하는 함수\n",
        "        \"\"\"\n",
        "        return {idx: val for idx, val in enumerate(df[feature].unique())}\n",
        "    \n",
        "    def get_user_item_dict(self):\n",
        "        \"\"\"\n",
        "        user-item dictionary를 만드는 함수\n",
        "        \"\"\"\n",
        "        user_item_dict = defaultdict(list)\n",
        "        for _, row in self.ratings.iterrows():\n",
        "            user_idx = int(row['user_idx'])\n",
        "            item_idx = int(row['item_idx']) \n",
        "            user_item_dict[user_idx].append(item_idx)\n",
        "        return user_item_dict\n",
        "    \n",
        "    def train_valid_split(self, valid_sample_size=10, seed=42):\n",
        "        \"\"\"\n",
        "        train, valid 데이터셋을 나누는 함수\n",
        "        \"\"\"\n",
        "        np.random.seed(seed)\n",
        "        train = {}\n",
        "        valid = {}\n",
        "        for user, item in self.user_item_dict.items():\n",
        "            valid_item = list(np.random.choice(item, valid_sample_size, replace=False, ))\n",
        "            train_item = list(set(item) - set(valid_item))\n",
        "            train[user] = train_item\n",
        "            valid[user] = valid_item\n",
        "        return train, valid\n",
        "\n",
        "    def get_matrix(self, user_list:List[int], trainyn:bool=True):\n",
        "        \"\"\"\n",
        "        AutoEncoder 모델에 입력할 데이터를 만들기 위한 함수\n",
        "        \"\"\"\n",
        "        mat = torch.zeros((len(user_list), self.item_num))\n",
        "        for idx, user in enumerate(user_list):\n",
        "            if trainyn:\n",
        "                mat[idx, self.train_dict[user]] = 1\n",
        "            else:\n",
        "                mat[idx, self.train_dict[user] + self.valid_dict[user]] = 1\n",
        "        return mat\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        DataLoader에서 데이터셋의 크기를 구하기 위한 함수\n",
        "        \"\"\"\n",
        "        return len(self.users)\n",
        "    \n",
        "    def __getitem__(self, idx:int):\n",
        "        \"\"\"\n",
        "        DataLoader에서 index를 통해 데이터를 불러오기 위한 함수\n",
        "        \"\"\"\n",
        "        return self.users[idx]\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MODELING\n",
        "- 주어진 문제를 잘 해석하고 해결하는 모델을 만드는 단계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, user_num:int, item_num:int, hidden_dim:int):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.user_num = user_num\n",
        "        self.item_num = item_num\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.encoder = torch.nn.Linear(item_num, hidden_dim)\n",
        "        self.decoder = torch.nn.Linear(hidden_dim, item_num)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = torch.sigmoid(self.encoder(x))\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = AEDataSet(ratings)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "model = AutoEncoder(user_num=dataset.user_num, item_num=dataset.item_num, hidden_dim=config['batch_size'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0.5224, -0.1163,  0.2507,  ..., -0.2362,  0.0164,  0.2071],\n",
            "        [-0.5158, -0.1241,  0.2517,  ..., -0.2283,  0.0133,  0.1998],\n",
            "        [-0.5103, -0.1217,  0.2482,  ..., -0.2341,  0.0120,  0.2064],\n",
            "        ...,\n",
            "        [-0.5203, -0.1394,  0.2582,  ..., -0.2470,  0.0171,  0.2188],\n",
            "        [-0.5162, -0.1293,  0.2596,  ..., -0.2358,  0.0100,  0.1923],\n",
            "        [-0.5004, -0.1155,  0.2841,  ..., -0.2161,  0.0232,  0.1940]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# I/O 실험\n",
        "for idx, user in enumerate(dataloader):\n",
        "    user = user.tolist()\n",
        "    mat = dataset.get_matrix(user, trainyn=False)\n",
        "    output = model(mat)\n",
        "    print(output)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### TRAINING & VALIDATION\n",
        "- 지표(METRICS) 설정\n",
        "- TRAIN과 VALIDATE를 반복하며 최적화 (하이퍼 파라미터, 모델 학습 주기 등)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "### METRICS ### \n",
        "def get_ndcg(pred_list, true_list, k=config['topk']):\n",
        "    def dcg(scores):\n",
        "        return np.sum([rel / np.log2(idx + 2) for idx, rel in enumerate(scores)])\n",
        "\n",
        "    relevance_scores = [1 if pred in true_list else 0 for pred in pred_list[:k]]\n",
        "\n",
        "    ideal_scores = [1] * min(len(true_list), k)\n",
        "    \n",
        "    dcg_value = dcg(relevance_scores)\n",
        "    idcg_value = dcg(ideal_scores)\n",
        "    \n",
        "    return dcg_value / idcg_value if idcg_value > 0 else 0\n",
        "\n",
        "def get_hit(pred_list, true_list):\n",
        "    hit_list = set(true_list) & set(pred_list)\n",
        "    hit = len(hit_list) / len(true_list)\n",
        "    return hit\n",
        "\n",
        "def train(model, dataloader, dataset, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    for idx, users in enumerate(dataloader):\n",
        "        users = users.tolist()\n",
        "        mat = dataset.get_matrix(users, trainyn=False)\n",
        "        output = model(mat)\n",
        "        loss = criterion(output, mat)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('Epoch: %d, Loss: %.4f' % (epoch+1, loss.item()))\n",
        "\n",
        "def evalutate(model, dataloader, dataset):\n",
        "    NDCG = 0\n",
        "    HIT = 0 \n",
        "    with torch.no_grad():\n",
        "        for idx, users in enumerate(dataloader):\n",
        "            users = users.tolist()\n",
        "            mat = dataset.get_matrix(users, trainyn=True)\n",
        "            output = model(mat)\n",
        "            output = torch.softmax(output, dim=1)\n",
        "            output[mat == 1] = -1\n",
        "            rec_list = output.argsort(dim = 1)\n",
        "            for user, rec in zip(users, rec_list):\n",
        "                pred_list = rec[-config['topk']:].tolist()\n",
        "                true_list = dataset.valid_dict[user]\n",
        "                ndcg = get_ndcg(pred_list, true_list)\n",
        "                hit = get_hit(pred_list, true_list)\n",
        "                NDCG += ndcg\n",
        "                HIT += hit\n",
        "    NDCG = NDCG / len(dataloader.dataset)\n",
        "    HIT = HIT / len(dataloader.dataset)\n",
        "    print('NDCG: %.4f, HIT: %.4f' % (NDCG, HIT))\n",
        "    return NDCG, HIT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Loss: 347.3615\n",
            "NDCG: 0.1078, HIT: 0.1179\n",
            "Epoch: 2, Loss: 2114.5432\n",
            "NDCG: 0.1296, HIT: 0.1408\n",
            "Epoch: 3, Loss: 301.1130\n",
            "NDCG: 0.1392, HIT: 0.1516\n",
            "Epoch: 4, Loss: 190.2558\n",
            "NDCG: 0.1550, HIT: 0.1689\n",
            "Epoch: 5, Loss: 354.0776\n",
            "NDCG: 0.1706, HIT: 0.1869\n",
            "Epoch: 6, Loss: 4388.2959\n",
            "NDCG: 0.1875, HIT: 0.2079\n",
            "Epoch: 7, Loss: 167.9472\n",
            "NDCG: 0.2020, HIT: 0.2215\n",
            "Epoch: 8, Loss: 191.7677\n",
            "NDCG: 0.2226, HIT: 0.2441\n",
            "Epoch: 9, Loss: 374.8484\n",
            "NDCG: 0.2371, HIT: 0.2595\n",
            "Epoch: 10, Loss: 3298.1851\n",
            "NDCG: 0.2425, HIT: 0.2690\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
        "for epoch in range(config['num_epoch']):\n",
        "    train(model, dataloader, dataset, optimizer, criterion, epoch)\n",
        "    evalutate(model, dataloader, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### INFERENCE & POSTPROCESSING\n",
        "- 서비스에 올라간 모델이 추론하는 파트\n",
        "- API 정의 (w/BE)\n",
        "    - request : user의 uid\n",
        "    - response : recommendation item \n",
        "    - 실제론 더 복잡!\n",
        "- 후처리 작업\n",
        "    - e.g. 판매 금지 리스트(셀러 사이드에서 올라온 부적절한 상품 등)\n",
        "    - e.g. 추가 튜닝 - 추천 품질을 올리기 위한 re-ranking 등"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[3681, 1079, 1270, 2628, 1266, 2470, 3361, 2321, 2100, 913]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def inference(model, dataloader, dataset, user_id):\n",
        "    with torch.inference_mode():\n",
        "        user = dataset.user2idx[user_id]\n",
        "        mat = dataset.get_matrix([user], trainyn=False)\n",
        "        output = model(mat)\n",
        "        output = torch.softmax(output, dim=1)\n",
        "        output[mat == 1] = -1\n",
        "        rec_list = output.argsort(dim = 1)\n",
        "        pred_list = rec_list[0][-config['topk']:].tolist()\n",
        "        return [dataset.idx2item[idx] for idx in pred_list] \n",
        "    \n",
        "random_user = np.random.choice(ratings['user_id'].unique())\n",
        "inference(model, dataloader, dataset, random_user)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PACKAGING & SERVING\n",
        "- MLOps 관점에서 모델을 패키징하고 서빙하는 파이프라인을 만드는 작업"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MONITORING\n",
        "- 추천이 서비스에서 잘 이루어지고 있는지 모니터링\n",
        "- e.g. API에서 에러가 나지 않았는 지\n",
        "- e.g. 추천이 제공되고 있는 아이템들은 적절한 지\n",
        "- e.g. 지표가 하락하지 않았는 지"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
